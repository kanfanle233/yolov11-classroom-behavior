import argparse
import json
import subprocess
import sys
import time
import datetime
import shutil
from pathlib import Path


# ==========================================
# 0. è®©è„šæœ¬åœ¨ä»»ä½•ç›®å½•è¿è¡Œéƒ½èƒ½ import scripts.intelligence_class._utils.pathing
#    ï¼ˆä»…ç”¨äºè·¯å¾„å·¥å…·å¯¼å…¥ï¼›ä¸å½±å“ä½ åŸæœ‰é€»è¾‘ï¼‰
# ==========================================
_this = Path(__file__).resolve()
for p in [_this] + list(_this.parents):
    if (p / "data").exists() and (p / "scripts").exists():
        sys.path.insert(0, str(p))
        break

from scripts.intelligence_class._utils.pathing import find_project_root, find_sibling_script


# ==========================================
# 1. è·¯å¾„ä¸ç¯å¢ƒé…ç½®
# ==========================================

def resolve_paths(custom_index_path=None, custom_out_root=None):
    """
    è§£æé¡¹ç›®æ ¸å¿ƒè·¯å¾„
    åŸºäºå½“å‰è„šæœ¬ä½ç½®ï¼šYOLOv11/scripts/intelligence_class/02_batch_run.py
    """
    current_file = Path(__file__).resolve()

    # âœ… ç»Ÿä¸€ï¼šå‘ä¸Šå¯»æ‰¾é¡¹ç›®æ ¹ç›®å½• (YOLOv11) â€”â€” ä¸å†ä¾èµ– parents[2]
    project_root = find_project_root(current_file)

    # âœ… ç»Ÿä¸€ï¼šå•è§†é¢‘æ‰§è¡Œå™¨ï¼š01_run_single_video.py â€”â€” ä¸å†è¦æ±‚åœ¨åŒä¸€ç›®å½•
    target_script = find_sibling_script(
        "01_run_single_video.py",
        start_file=current_file,
        project_root=project_root
    )

    index_file = project_root / "output" / "dataset_index.json"
    if custom_index_path:
        index_file = Path(custom_index_path).resolve()

    output_root = project_root / "output"
    if custom_out_root:
        output_root = Path(custom_out_root).resolve()

    batch_dir = output_root / "_batch"
    paths = {
        "root": project_root,
        "target_script": target_script,
        "index_file": index_file,
        "output_root": output_root,
        "batch_dir": batch_dir,
        "failure_log": batch_dir / "batch_failures.jsonl",
        "report_file": batch_dir / "batch_report.json",
    }

    if not paths["target_script"].exists():
        print(f"[FATAL] æ‰¾ä¸åˆ°å•è§†é¢‘æ‰§è¡Œå™¨: {paths['target_script']}")
        sys.exit(1)

    return paths


# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘å‡½æ•°
# ==========================================

def load_index(index_path: Path):
    """åŠ è½½å¹¶æ ¡éªŒç´¢å¼•æ–‡ä»¶"""
    if not index_path.exists():
        print(f"[FATAL] ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_path}")
        print("è¯·å…ˆè¿è¡Œ 000.py (æˆ– 01_scan_dataset.py) ç”Ÿæˆç´¢å¼•ã€‚")
        sys.exit(1)

    try:
        with open(index_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            return data.get("videos", [])
    except Exception as e:
        print(f"[FATAL] ç´¢å¼•æ–‡ä»¶æŸå: {e}")
        sys.exit(1)


def is_complete_outdir(out_dir: Path, min_bytes: int = 256, marker_name: str = "actions.jsonl") -> bool:
    """
    åˆ¤å®šè¾“å‡ºç›®å½•æ˜¯å¦å®Œæˆï¼šéœ€å­˜åœ¨ marker æ–‡ä»¶ä¸”å¤§å°è¾¾åˆ°é˜ˆå€¼ã€‚
    """
    if not out_dir.exists():
        return False

    marker_path = out_dir / marker_name
    if not marker_path.exists():
        return False

    if min_bytes <= 0:
        return True

    try:
        return marker_path.stat().st_size >= min_bytes
    except OSError:
        return False


def compute_out_dirs(output_root: Path, view_code: str, video_id: str):
    """
    æ–°ç»“æ„ï¼šoutput/<view_code>/<video_id>/
    æ—§ç»“æ„ï¼šoutput/<video_id>/
    """
    new_dir = output_root / view_code / video_id
    legacy_dir = output_root / video_id
    return new_dir, legacy_dir


def maybe_migrate_legacy(legacy_dir: Path, new_dir: Path, dry_run: bool, on_conflict: str = "skip"):
    """
    å¯é€‰ï¼šæŠŠæ—§ç»“æ„ç›®å½•ç§»åŠ¨åˆ°æ–°ç»“æ„ç›®å½•
    """
    if not legacy_dir.exists() or not legacy_dir.is_dir():
        return False

    new_dir.parent.mkdir(parents=True, exist_ok=True)

    if new_dir.exists():
        if on_conflict == "error":
            raise FileExistsError(f"Dest exists: {new_dir}")
        # skip
        return False

    if dry_run:
        print(f"[DRY] MIGRATE {legacy_dir} -> {new_dir}")
        return True

    shutil.move(str(legacy_dir), str(new_dir))
    print(f"[MIGRATE] {legacy_dir.name} -> {new_dir}")
    return True


def append_failure_log(log_path: Path, entry: dict, error_msg: str):
    """å°†å¤±è´¥ä¿¡æ¯è¿½åŠ å†™å…¥ JSONL"""
    record = {
        "time": datetime.datetime.now().isoformat(),
        "video_id": entry.get("video_id"),
        "view_code": entry.get("view_code") or entry.get("view"),
        "video_path": entry.get("video_path"),
        "error": str(error_msg).strip()
    }
    try:
        log_path.parent.mkdir(parents=True, exist_ok=True)
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"[WARN] æ— æ³•å†™å…¥å¤±è´¥æ—¥å¿—: {e}")


def save_report(report_path: Path, stats: dict, params: dict, failed_examples: list, start_time_iso: str,
                end_time_iso: str):
    """ä¿å­˜æœ€ç»ˆè¿è¡ŒæŠ¥å‘Š"""
    report = {
        "generated_at": datetime.datetime.now().isoformat(),
        "start_time": start_time_iso,
        "end_time": end_time_iso,
        "counts": stats,
        "params": params,
        "failed_examples": failed_examples
    }
    try:
        report_path.parent.mkdir(parents=True, exist_ok=True)
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[WARN] æ— æ³•ä¿å­˜æŠ¥å‘Š: {e}")


# ==========================================
# 3. ä¸»ç¨‹åº
# ==========================================

def main():
    parser = argparse.ArgumentParser(description="å¤§è§„æ¨¡è§†é¢‘åˆ†ææ‰¹å¤„ç†è°ƒåº¦å™¨ï¼ˆæŒ‰è§†è§’åˆ†å±‚è¾“å‡ºï¼‰")

    parser.add_argument("--index", type=str, default=None, help="ç´¢å¼•æ–‡ä»¶è·¯å¾„ (é»˜è®¤ output/dataset_index.json)")
    parser.add_argument("--out_root", type=str, default=None, help="è¾“å‡ºæ ¹ç›®å½• (é»˜è®¤ output/)")

    parser.add_argument("--views", type=str, default=None, help="åªå¤„ç†æŒ‡å®šè§†è§’ (å¦‚ rear,front,top1)")
    parser.add_argument("--limit", type=int, default=0, help="å¤„ç†æ•°é‡é™åˆ¶ (0=ä¸é™)")
    parser.add_argument("--start", type=int, default=0, help="ä»ç­›é€‰ååˆ—è¡¨ç¬¬ N ä¸ªå¼€å§‹ (ç”¨äºæ–­ç‚¹)")
    parser.add_argument("--end", type=int, default=None, help="ç›´åˆ°ç­›é€‰ååˆ—è¡¨ç¬¬ N ä¸ªç»“æŸ(ä¸å«)")

    parser.add_argument("--skip_existing", type=int, default=1, help="è·³è¿‡å·²å®Œæˆ (1=Yes, 0=No)")
    parser.add_argument("--min_bytes", type=int, default=256, help="åˆ¤å®šå®Œæˆçš„ actions.jsonl æœ€å°å­—èŠ‚æ•°é˜ˆå€¼")
    parser.add_argument("--short_video", type=int, default=0, help="çŸ­è§†é¢‘æ¨¡å¼ï¼šé™ä½ min_bytes ä¸è½¨è¿¹é—¨æ§›")
    parser.add_argument("--migrate_legacy", type=int, default=0,
                        help="å‘ç°æ—§ç»“æ„å·²å®Œæˆæ—¶ï¼Œæ˜¯å¦è‡ªåŠ¨æ¬è¿åˆ°æ–°ç»“æ„ (1=Yes,0=No)")
    parser.add_argument("--dry_run", action="store_true", help="ä»…æ‰“å°è®¡åˆ’ï¼Œä¸æ‰§è¡Œ")
    parser.add_argument("--stream_output", type=int, default=0,
                        help="å®æ—¶è¾“å‡ºå­è¿›ç¨‹æ—¥å¿— (1=Yes, 0=No)")

    args = parser.parse_args()

    paths = resolve_paths(args.index, args.out_root)
    python_exe = sys.executable
    log_dir = paths["batch_dir"] / "logs"
    if int(args.short_video) == 1 and args.min_bytes == 256:
        args.min_bytes = 128

    print("=" * 60)
    print("ğŸš€ æ‰¹å¤„ç†è°ƒåº¦å™¨å¯åŠ¨ (Batch Scheduler)")
    print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {paths['root']}")
    print(f"ğŸ“ è¾“å‡ºæ ¹ç›®å½•: {paths['output_root']}")
    print("=" * 60)

    all_videos = load_index(paths["index_file"])

    # --- 1. è§†è§’ç­›é€‰ ---
    allowed_views = args.views.split(",") if args.views else None
    target_videos = []
    for v in all_videos:
        v_code = v.get("view_code") or v.get("view") or "unknown"
        if allowed_views and v_code not in allowed_views:
            continue
        target_videos.append(v)

    total_filtered = len(target_videos)
    slice_start = max(0, args.start)
    slice_end = args.end if args.end is not None else total_filtered
    slice_end = min(slice_end, total_filtered)
    if args.limit > 0:
        slice_end = min(slice_end, slice_start + args.limit)

    if slice_start >= total_filtered:
        print(f"[WARN] èµ·å§‹ç´¢å¼• {slice_start} è¶…å‡ºä»»åŠ¡æ€»æ•° {total_filtered}ï¼Œæ— ä»»åŠ¡å¯åšã€‚")
        sys.exit(0)

    # åˆå§‹ä»»åŠ¡åˆ—è¡¨ï¼ˆåŸºäºç´¢å¼•èŒƒå›´ï¼‰
    initial_tasks = target_videos[slice_start:slice_end]

    stats = {"total_in_range": len(initial_tasks), "success": 0, "failed": 0, "skipped": 0, "migrated": 0}

    # --- 2. æ™ºèƒ½è·³è¿‡é€»è¾‘ (ä¿®æ”¹ç‚¹: é¢„å¤„ç†è¿‡æ»¤) ---
    final_tasks = []
    if args.skip_existing == 1:
        print(f"ğŸ” [æ™ºèƒ½è¿‡æ»¤] æ­£åœ¨æ‰«æå·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶...")
        skipped_count = 0

        for entry in initial_tasks:
            video_id = entry.get("video_id")
            view_code = entry.get("view_code") or entry.get("view") or "unknown"

            # è®¡ç®—è·¯å¾„
            out_dir_new, out_dir_legacy = compute_out_dirs(paths["output_root"], view_code, video_id)

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ (åŒæ—¶æ£€æŸ¥æ–°æ—§ç»“æ„)
            is_done_new = is_complete_outdir(out_dir_new, min_bytes=args.min_bytes)
            is_done_legacy = is_complete_outdir(out_dir_legacy, min_bytes=args.min_bytes)

            # å¦‚æœå­˜åœ¨ä¸”ä¸è¿ç§»ï¼Œåˆ™è·³è¿‡
            should_skip = False
            if is_done_new:
                should_skip = True
            elif is_done_legacy:
                if args.migrate_legacy == 1:
                    # å¦‚æœéœ€è¦è¿ç§»ï¼Œåˆ™ä¸èƒ½ä»ä»»åŠ¡åˆ—è¡¨ç§»é™¤ï¼Œéœ€è¦è¿›å…¥ä¸»å¾ªç¯å¤„ç†è¿ç§»
                    should_skip = False
                else:
                    should_skip = True

            if should_skip:
                skipped_count += 1
            else:
                final_tasks.append(entry)

        stats["skipped"] = skipped_count
        print(f"â© å·²è‡ªåŠ¨è·³è¿‡: {skipped_count} ä¸ªå·²å®Œæˆä»»åŠ¡")
        print(f"â–¶ï¸ å‰©ä½™å¾…æ‰§è¡Œ: {len(final_tasks)} ä¸ªä»»åŠ¡")
    else:
        final_tasks = initial_tasks

    tasks = final_tasks

    print("-" * 60)
    failed_examples = []
    t0 = time.time()
    start_iso = datetime.datetime.now().isoformat()

    # --- 3. æ‰§è¡Œå¾ªç¯ ---
    for i, entry in enumerate(tasks):
        video_id = entry.get("video_id")
        view_code = entry.get("view_code") or entry.get("view") or "unknown"

        if not video_id:
            stats["failed"] += 1
            append_failure_log(paths["failure_log"], entry, "Missing video_id")
            continue

        raw_path = entry.get("video_path")
        if raw_path is None:
            stats["failed"] += 1
            append_failure_log(paths["failure_log"], entry, "Missing video_path")
            continue

        video_abs_path = Path(raw_path) if Path(raw_path).is_absolute() else (paths["root"] / raw_path)
        if not video_abs_path.exists():
            stats["failed"] += 1
            append_failure_log(paths["failure_log"], entry, f"Missing video file: {video_abs_path}")
            continue
        out_dir_new, out_dir_legacy = compute_out_dirs(paths["output_root"], view_code, video_id)

        # è¿›åº¦å‰ç¼€ (æ˜¾ç¤ºå½“å‰å‰©ä½™ä»»åŠ¡ä¸­çš„è¿›åº¦)
        prefix = f"[{i + 1}/{len(tasks)}][{video_id}]"

        # 3.1 å†æ¬¡æ£€æŸ¥ (é˜²æ­¢è¾¹ç¼˜æƒ…å†µæˆ–å¤„ç†è¿ç§»)
        if args.skip_existing == 1:
            if is_complete_outdir(out_dir_new, min_bytes=args.min_bytes):
                # ç†è®ºä¸Šä¸ä¼šè¿›è¿™é‡Œï¼Œé™¤éé¢„ç­›é€‰åæ–‡ä»¶çªç„¶ç”Ÿæˆï¼Œä½†ä¸ºäº†å®‰å…¨ä¿ç•™
                print(f"{prefix} SKIP (å·²å­˜åœ¨)")
                continue

            if is_complete_outdir(out_dir_legacy, min_bytes=args.min_bytes):
                # æ—§ç»“æ„å­˜åœ¨ï¼šå¯é€‰è¿ç§»
                if args.migrate_legacy == 1:
                    moved = maybe_migrate_legacy(out_dir_legacy, out_dir_new, dry_run=args.dry_run, on_conflict="skip")
                    if moved:
                        stats["migrated"] += 1
                        print(f"{prefix} SKIP (å·²è¿ç§»)")
                        stats["skipped"] += 1  # è¿ç§»ä¹Ÿç®—å¤„ç†å®Œæˆ
                        continue
                else:
                    print(f"{prefix} SKIP (æ—§ç»“æ„å·²å®Œæˆ)")
                    continue

        # 3.2 åˆ›å»ºæ–°è¾“å‡ºç›®å½•
        if not args.dry_run:
            out_dir_new.mkdir(parents=True, exist_ok=True)

        # 3.3 æ„é€ å‘½ä»¤
        cmd = [
            python_exe, str(paths["target_script"]),
            "--video", str(video_abs_path),
            "--video_id", str(video_id),
            "--out_dir", str(out_dir_new),
        ]
        if int(args.short_video) == 1:
            cmd += ["--short_video", "1"]

        if args.dry_run:
            print(f"{prefix} [DRY-RUN] CMD: {' '.join(cmd)}")
            stats["success"] += 1
            continue

        # 3.4 å®é™…æ‰§è¡Œ
        loop_start = time.time()
        try:
            if args.stream_output == 1:
                subprocess.run(cmd, check=True)
            else:
                log_dir.mkdir(parents=True, exist_ok=True)
                log_path = log_dir / f"{video_id}.log"
                with log_path.open("w", encoding="utf-8") as f:
                    subprocess.run(
                        cmd,
                        check=True,
                        stdout=f,
                        stderr=subprocess.STDOUT,
                        text=True,
                        encoding="utf-8",
                        errors="replace",
                    )

            duration = time.time() - loop_start
            print(f"{prefix} SUCCESS ({duration:.1f}s)")
            stats["success"] += 1

        except subprocess.CalledProcessError as e:
            stats["failed"] += 1
            err_msg = e.stderr.strip() if e.stderr else "Unknown Subprocess Error"
            if args.stream_output == 1:
                err_msg = f"Exit {e.returncode} (see console logs)"
            short_err = err_msg[-300:].replace("\n", " ")
            print(f"{prefix} FAILED (Exit {e.returncode}) -> {short_err}")

            append_failure_log(paths["failure_log"], entry, err_msg)
            if len(failed_examples) < 20:
                failed_examples.append({"id": video_id, "error": short_err})

        except Exception as e:
            stats["failed"] += 1
            print(f"{prefix} ERROR (System) -> {str(e)}")

            append_failure_log(paths["failure_log"], entry, str(e))
            if len(failed_examples) < 20:
                failed_examples.append({"id": video_id, "error": str(e)})

    total_time = time.time() - t0
    end_iso = datetime.datetime.now().isoformat()

    params_log = {k: v for k, v in vars(args).items()}
    save_report(paths["report_file"], stats, params_log, failed_examples, start_iso, end_iso)

    print("=" * 60)
    print(f"ğŸ æ‰¹å¤„ç†ç»“æŸ (è€—æ—¶: {total_time:.1f}s)")
    print(
        f"ğŸ“Š ç»Ÿè®¡: èŒƒå›´æ€»æ•° {stats['total_in_range']} | è·³è¿‡ {stats['skipped']} | æˆåŠŸ {stats['success']} | å¤±è´¥ {stats['failed']}")
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {paths['report_file']}")
    if stats["failed"] > 0:
        print(f"âš ï¸ å¤±è´¥æ—¥å¿—: {paths['failure_log']}")
    print("=" * 60)


if __name__ == "__main__":
    main()
