# scripts/intelligence_class/tools/xx_generate_timeline_viz.py
import argparse
import json
import math
import sys
from pathlib import Path
from collections import defaultdict

try:
    from scripts.intelligence_class._utils.action_map import ACTION_MAP, LABEL_NORMALIZE
except ModuleNotFoundError:
    PROJECT_ROOT = Path(__file__).resolve().parents[3]
    sys.path.insert(0, str(PROJECT_ROOT))
    from scripts.intelligence_class._utils.action_map import ACTION_MAP, LABEL_NORMALIZE


def load_jsonl(path: Path):
    data = []
    if not path or not path.exists():
        return data
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                try:
                    data.append(json.loads(line))
                except Exception:
                    pass
    return data


# =========================================================
# ç»‘å®š track_idï¼šç”¨ pose_tracks_smooth.jsonl åšèº«ä»½é”šç‚¹
# =========================================================

def _iou_xyxy(a, b):
    ax1, ay1, ax2, ay2 = map(float, a)
    bx1, by1, bx2, by2 = map(float, b)
    ix1, iy1 = max(ax1, bx1), max(ay1, by1)
    ix2, iy2 = min(ax2, bx2), min(ay2, by2)
    iw, ih = max(0.0, ix2 - ix1), max(0.0, iy2 - iy1)
    inter = iw * ih
    if inter <= 0:
        return 0.0
    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)
    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)
    denom = area_a + area_b - inter
    return float(inter / denom) if denom > 0 else 0.0


def _index_tracks_by_frame(tracks_jsonl: Path):
    """è¿”å›: {frame_idx: [(track_id, bbox_xyxy), ...]}"""
    idx = {}
    if not tracks_jsonl or not tracks_jsonl.exists():
        return idx

    for row in load_jsonl(tracks_jsonl):
        f = row.get("frame_idx", row.get("frame"))
        if f is None:
            continue
        f = int(f)

        people = []
        for p in row.get("persons", []) or []:
            tid = p.get("track_id")
            bbox = p.get("bbox")
            if tid is None or bbox is None:
                continue
            people.append((int(tid), bbox))

        idx[f] = people

    return idx


def _match_tid(det_bbox, people, iou_thr=0.15):
    if det_bbox is None or not people:
        return 0
    best_tid, best_iou = 0, 0.0
    for tid, tb in people:
        v = _iou_xyxy(det_bbox, tb)
        if v > best_iou:
            best_iou, best_tid = v, tid
    return best_tid if best_iou >= iou_thr else 0


def _norm_action(label: str) -> str:
    if not label:
        return ""
    s = str(label).strip()
    s_low = s.lower()
    # æœ‰çš„labelæ˜¯ä¸­æ–‡æˆ–å…¶ä»–æ ¼å¼ï¼Œå°±å…ˆæŒ‰åŸæ ·ï¼›æœ‰æ˜ å°„çš„å°±æ˜ å°„
    return LABEL_NORMALIZE.get(s_low, LABEL_NORMALIZE.get(s, s))


def compress_timeline(
    frames_data: list,
    fps: float = 25.0,
    gap_sec: float = 0.2,
    min_event_sec: float = 0.2,
) -> list:
    """æ ¸å¿ƒç®—æ³•ï¼šå°†ç¦»æ•£çš„å¸§å‹ç¼©ä¸ºè¿ç»­çš„æ—¶é—´æ®µ (Gantt Blocks)"""
    if not frames_data:
        return []

    gap_frames = max(1, math.ceil(gap_sec * fps))
    min_event_frames = max(1, math.ceil(min_event_sec * fps))

    # 1. æŒ‰ track_id åˆ†ç»„
    by_track = defaultdict(list)
    for item in frames_data:
        tid = item.get("track_id")
        action = item.get("action") or item.get("label")
        fidx = item.get("frame_idx")
        if fidx is None:
            fidx = item.get("frame")

        if tid is not None and action and fidx is not None:
            by_track[int(tid)].append({"frame": int(fidx), "action": action})

    compressed_events = []

    # 2. å¯¹æ¯ä¸ªäººçš„è½¨è¿¹è¿›è¡Œå‹ç¼©
    for tid, trace in by_track.items():
        trace.sort(key=lambda x: x["frame"])
        if not trace:
            continue

        current_event = None
        for point in trace:
            f = point["frame"]
            act = point["action"]

            if current_event is None:
                current_event = {"track_id": tid, "action": act, "start_frame": f, "end_frame": f}
                continue

            is_same_action = (act == current_event["action"])
            is_continuous = (f - current_event["end_frame"] <= gap_frames)

            if is_same_action and is_continuous:
                current_event["end_frame"] = f
            else:
                if (current_event["end_frame"] - current_event["start_frame"]) >= min_event_frames:
                    compressed_events.append(current_event)
                current_event = {"track_id": tid, "action": act, "start_frame": f, "end_frame": f}

        if current_event and (current_event["end_frame"] - current_event["start_frame"]) >= min_event_frames:
            compressed_events.append(current_event)

    # 3. æ ¼å¼åŒ–è¾“å‡º
    final_output = []
    for evt in compressed_events:
        act = evt["action"]
        final_output.append({
            "track_id": evt["track_id"],
            "action": act,
            "action_id": ACTION_MAP.get(act, 0),
            "start": round(evt["start_frame"] / fps, 2),
            "end": round(evt["end_frame"] / fps, 2),
            "frame_idx": evt["start_frame"],
            "duration": round((evt["end_frame"] - evt["start_frame"]) / fps, 2),
        })

    final_output.sort(key=lambda x: x["start"])
    return final_output


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--case_dir", required=True, help="æ¡ˆä¾‹è¾“å‡ºç›®å½•, e.g. output/rear__001")
    parser.add_argument("--fps", type=float, default=25.0)
    parser.add_argument("--short_video", type=int, default=0, help="use shorter gap/min durations for short clips")
    parser.add_argument("--gap_sec", type=float, default=None, help="max gap (seconds) to merge actions")
    parser.add_argument("--min_event_sec", type=float, default=None, help="min duration (seconds) to keep an event")

    # æ–°å¢ï¼šå¼ºåˆ¶é€‰æ‹©æ•°æ®æº
    # auto: ä¿æŒåŸé€»è¾‘ï¼ˆä¼˜å…ˆ actions.jsonlï¼Œæ‰¾ä¸åˆ°æ‰ç”¨ *_behavior.jsonlï¼‰
    # actions: åªç”¨ actions.jsonl
    # behavior: åªç”¨ *_behavior.jsonl
    parser.add_argument("--source", choices=["auto", "actions", "behavior"], default="auto")

    # æ–°å¢ï¼šå½“ source=behavior æ—¶ï¼Œç”¨ tracks æŠŠ det bbox ç»‘å®šåˆ°ç¨³å®š track_id
    parser.add_argument(
        "--tracks",
        type=str,
        default="",
        help="ç”¨äºåˆ†é… track_id çš„ tracks.jsonlï¼ˆä¾‹å¦‚ pose_tracks_smooth.jsonlï¼‰ã€‚ä¸ºç©ºåˆ™ä¸ç»‘å®šã€‚",
    )

    args = parser.parse_args()

    case_dir = Path(args.case_dir)
    if not case_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {case_dir}")
        return

    # 1. é€‰æ‹©æ•°æ®æº
    source_file = None
    source_type = None

    actions_file = case_dir / "actions.jsonl"
    behavior_cands = list(case_dir.glob("*_behavior.jsonl"))
    behavior_file = behavior_cands[0] if behavior_cands else None

    if args.source == "actions":
        source_file, source_type = actions_file, "actions"
    elif args.source == "behavior":
        source_file, source_type = behavior_file, "yolo_behavior"
    else:
        # auto
        if actions_file.exists():
            source_file, source_type = actions_file, "actions"
        elif behavior_file and behavior_file.exists():
            source_file, source_type = behavior_file, "yolo_behavior"

    if not source_file or not source_file.exists():
        print(f"âš ï¸  åœ¨ {case_dir} ä¸­æœªæ‰¾åˆ°å¯ç”¨æ•°æ®æºï¼šactions.jsonl æˆ– *_behavior.jsonl")
        with open(case_dir / "timeline_viz.json", "w", encoding="utf-8") as f:
            json.dump({"items": [], "fps": args.fps}, f)
        return

    print(f"ğŸš€ æ­£åœ¨å¤„ç† Timeline: {source_file.name} ({source_type})")

    # 2. åŠ è½½
    raw_data = load_jsonl(source_file)

    # 3. å¦‚ä¸º behaviorï¼šå±•å¹³ +ï¼ˆå¯é€‰ï¼‰ç»‘å®š track_id
    if source_type == "yolo_behavior":
        tracks_idx = {}
        tracks_path = Path(args.tracks) if args.tracks else None
        if tracks_path and not tracks_path.is_absolute():
            # ç›¸å¯¹è·¯å¾„é»˜è®¤ä» case_dir é‡Œæ‰¾
            tracks_path = (case_dir / tracks_path).resolve()

        if tracks_path and tracks_path.exists():
            tracks_idx = _index_tracks_by_frame(tracks_path)
            print(f"ğŸ§· tracks ç»‘å®šå¯ç”¨: {tracks_path.name} (frames={len(tracks_idx)})")
        else:
            if args.tracks:
                print(f"âš ï¸  tracks æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡ç»‘å®š: {tracks_path}")

        flat_data = []
        for row in raw_data:
            fidx = row.get("frame_idx", row.get("frame"))
            if fidx is None:
                continue
            fidx = int(fidx)

            # å…¼å®¹ç»“æ„1ï¼š{frame_idx, dets:[{label, xyxy, ...}]}
            if "dets" in row:
                people = tracks_idx.get(fidx, []) if tracks_idx else []
                for d in row.get("dets", []) or []:
                    lbl = _norm_action(d.get("label") or d.get("action") or d.get("cls"))
                    if not lbl:
                        continue

                    # å– bboxï¼šä¼˜å…ˆ xyxyï¼ˆcase_det/jsonl æ˜¯è¿™ä¸ªå­—æ®µï¼‰ï¼Œå…¶æ¬¡ bbox
                    det_bbox = d.get("xyxy") or d.get("bbox")

                    # ä¼˜å…ˆç”¨å·²æœ‰ track_idï¼›æ²¡æœ‰å°±ç”¨ tracks ç»‘å®š
                    tid = d.get("track_id")
                    if tid is None:
                        tid = d.get("id")
                    if tid is None:
                        tid = _match_tid(det_bbox, people) if tracks_idx else 0

                    # æœ€ç»ˆ action å†™æˆå‰ç«¯åŠ¨ä½œåï¼ˆä¿æŒå‰ç«¯é¢œè‰²é€»è¾‘ï¼‰
                    flat_data.append({"frame_idx": fidx, "track_id": int(tid), "action": lbl})

            # å…¼å®¹ç»“æ„2ï¼š{frame_idx, persons:[{track_id, action, ...}]}
            elif "persons" in row:
                for p in row.get("persons", []) or []:
                    lbl = _norm_action(p.get("action") or p.get("label"))
                    if not lbl:
                        continue
                    flat_data.append({"frame_idx": fidx, "track_id": int(p.get("track_id", 0)), "action": lbl})

        raw_data = flat_data

    # 4. å‹ç¼©ç”Ÿæˆ Gantt æ•°æ®
    gap_sec = args.gap_sec
    min_event_sec = args.min_event_sec
    if gap_sec is None:
        gap_sec = 0.12 if int(args.short_video) == 1 else 0.2
    if min_event_sec is None:
        min_event_sec = 0.12 if int(args.short_video) == 1 else 0.2

    timeline_items = compress_timeline(raw_data, args.fps, gap_sec=gap_sec, min_event_sec=min_event_sec)

    # 5. ä¿å­˜
    out_file = case_dir / "timeline_viz.json"
    output_obj = {
        "meta": {
            "source": source_file.name,
            "source_type": source_type,
            "fps": args.fps,
            "total_events": len(timeline_items),
            "track_ids": sorted(list(set(d["track_id"] for d in timeline_items))) if timeline_items else [],
        },
        "items": timeline_items,
    }

    with open(out_file, "w", encoding="utf-8") as f:
        json.dump(output_obj, f, ensure_ascii=False, indent=2)

    print(f"âœ… å·²ç”Ÿæˆ Timeline æ•°æ®: {out_file} (åŒ…å« {len(timeline_items)} ä¸ªäº‹ä»¶)")


if __name__ == "__main__":
    main()
